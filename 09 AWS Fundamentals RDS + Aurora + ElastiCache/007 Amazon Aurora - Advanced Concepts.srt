1
00:00:00,480 --> 00:00:01,589
So now let's discuss

2
00:00:01,589 --> 00:00:03,180
advanced concepts of Aurora

3
00:00:03,180 --> 00:00:05,250
that you need to know going into the exam.

4
00:00:05,250 --> 00:00:07,650
So let's talk about Replica Auto Scaling.

5
00:00:07,650 --> 00:00:09,330
So let's say we have a client

6
00:00:09,330 --> 00:00:12,330
and we have three Auroras instances right now.

7
00:00:12,330 --> 00:00:15,630
So one will be writing through the Writer Endpoint

8
00:00:15,630 --> 00:00:17,430
and the other two would be reading

9
00:00:17,430 --> 00:00:19,560
through the Reader Endpoint, okay?

10
00:00:19,560 --> 00:00:22,140
Now let's say that we are having many, many requests,

11
00:00:22,140 --> 00:00:24,600
read requests on the Reader Endpoint,

12
00:00:24,600 --> 00:00:27,150
and so therefore the Amazon Aurora databases

13
00:00:27,150 --> 00:00:29,460
have an increased CPU usage.

14
00:00:29,460 --> 00:00:32,310
In that case, we can set up replica auto-scaling

15
00:00:32,310 --> 00:00:35,010
and what this will do is that it will add, obviously,

16
00:00:35,010 --> 00:00:36,780
Amazon Aurora Replicas,

17
00:00:36,780 --> 00:00:39,060
and then what will happen is that automatically

18
00:00:39,060 --> 00:00:41,670
the Reader Endpoint is going to be extended

19
00:00:41,670 --> 00:00:44,550
to cover these new replicas,

20
00:00:44,550 --> 00:00:45,840
and therefore these new replicas

21
00:00:45,840 --> 00:00:47,820
will start receiving some traffic

22
00:00:47,820 --> 00:00:50,250
and the reads will be happening

23
00:00:50,250 --> 00:00:51,870
in a more distributed fashion,

24
00:00:51,870 --> 00:00:54,690
hopefully bringing down the overall CPU usage.

25
00:00:54,690 --> 00:00:56,493
So this is replica auto scaling.

26
00:00:57,780 --> 00:01:00,090
The second thing is Custom Endpoints.

27
00:01:00,090 --> 00:01:02,460
So let's say we have the same setup,

28
00:01:02,460 --> 00:01:05,970
but this time we have two different kinds of replicas.

29
00:01:05,970 --> 00:01:09,060
As you can see, we have some db.r3.large

30
00:01:09,060 --> 00:01:11,940
and some db.r5.2xlarge.

31
00:01:11,940 --> 00:01:15,750
So some Read Replicas are bigger than others.

32
00:01:15,750 --> 00:01:17,310
And the reason you would do this

33
00:01:17,310 --> 00:01:18,360
is that you want to define

34
00:01:18,360 --> 00:01:22,950
a subset of your Aurora instances as a Custom Endpoint.

35
00:01:22,950 --> 00:01:25,260
So let's say we define a Custom Endpoint

36
00:01:25,260 --> 00:01:28,800
on these two bigger Aurora instances.

37
00:01:28,800 --> 00:01:30,600
The reason we would do so is for example,

38
00:01:30,600 --> 00:01:34,410
that we know that these instances are more powerful

39
00:01:34,410 --> 00:01:36,120
and therefore they're going to be better

40
00:01:36,120 --> 00:01:40,320
to run analytical queries on these specific replicas.

41
00:01:40,320 --> 00:01:41,520
So when you do so,

42
00:01:41,520 --> 00:01:43,710
you have a Custom Endpoint that's defined.

43
00:01:43,710 --> 00:01:45,570
And when you have a Custom Endpoint,

44
00:01:45,570 --> 00:01:48,030
generally the Reader Endpoint itself

45
00:01:48,030 --> 00:01:50,490
is not used after defining Custom Endpoints.

46
00:01:50,490 --> 00:01:53,880
So it would not disappear, but you would not use it anymore.

47
00:01:53,880 --> 00:01:57,570
And what you would do, like practically speaking,

48
00:01:57,570 --> 00:01:59,910
is set up many Custom Endpoints

49
00:01:59,910 --> 00:02:02,070
for many different kind of workloads,

50
00:02:02,070 --> 00:02:05,070
therefore allowing you to query only a subset

51
00:02:05,070 --> 00:02:07,023
of your Aurora Replicas.

52
00:02:08,250 --> 00:02:09,900
Next we have Serverless.

53
00:02:09,900 --> 00:02:11,250
So this is going to give you

54
00:02:11,250 --> 00:02:13,680
automated database instantiation

55
00:02:13,680 --> 00:02:16,410
and auto-scaling based on actual usage,

56
00:02:16,410 --> 00:02:19,770
which is great when you have infrequent, intermittent,

57
00:02:19,770 --> 00:02:21,780
or unpredictable workloads.

58
00:02:21,780 --> 00:02:24,840
And therefore you don't need to do any capacity planning.

59
00:02:24,840 --> 00:02:28,050
You're going to pay per the second of each Aurora instance

60
00:02:28,050 --> 00:02:29,340
that is being spun up

61
00:02:29,340 --> 00:02:31,590
and this can be a lot more cost effective.

62
00:02:31,590 --> 00:02:32,640
So how does that work?

63
00:02:32,640 --> 00:02:36,090
Well, the client is going to talk to a proxy fleet

64
00:02:36,090 --> 00:02:37,560
that is managed by Aurora

65
00:02:37,560 --> 00:02:41,310
and in the backend, many Aurora instances will be created

66
00:02:41,310 --> 00:02:43,800
based on your workload in a serverless fashion,

67
00:02:43,800 --> 00:02:48,210
so you don't have to provision capacity at all in advance.

68
00:02:48,210 --> 00:02:50,640
Finally, we have Global Aurora.

69
00:02:50,640 --> 00:02:55,110
So in case we have a Aurora Cross Region Read Replica

70
00:02:55,110 --> 00:02:57,330
it's going to be very helpful for disaster recovery.

71
00:02:57,330 --> 00:02:58,830
Very simple to put in place,

72
00:02:58,830 --> 00:03:01,650
but you can also set up the Aurora Global Database,

73
00:03:01,650 --> 00:03:03,750
which is the recommended way of doing things today.

74
00:03:03,750 --> 00:03:05,790
In this case, you have one primary region

75
00:03:05,790 --> 00:03:07,620
where all the reads and writes happen,

76
00:03:07,620 --> 00:03:11,700
but you can set up up to five secondary read-only regions

77
00:03:11,700 --> 00:03:14,580
where the replication lag should be less than one second

78
00:03:14,580 --> 00:03:18,990
and up to 16 Read Replicas per secondary region.

79
00:03:18,990 --> 00:03:21,330
And this will help you decrease latency

80
00:03:21,330 --> 00:03:23,310
for the read workloads all over the world,

81
00:03:23,310 --> 00:03:26,910
but also in case you have a database outage in one region.

82
00:03:26,910 --> 00:03:29,640
Promoting another region for disaster recovery purposes

83
00:03:29,640 --> 00:03:32,370
has an RTO, so recovery time objective,

84
00:03:32,370 --> 00:03:33,240
of less than one minute.

85
00:03:33,240 --> 00:03:36,030
So it takes us in one minute to recover into another region.

86
00:03:36,030 --> 00:03:37,980
And here's a sentence you should look out for

87
00:03:37,980 --> 00:03:39,510
from an exam perspective,

88
00:03:39,510 --> 00:03:41,940
it takes on average less than one second

89
00:03:41,940 --> 00:03:43,830
to replicate data across region

90
00:03:43,830 --> 00:03:46,110
for your Aurora Global Database.

91
00:03:46,110 --> 00:03:47,820
So this is something that if you see an exam,

92
00:03:47,820 --> 00:03:50,910
it's a hint to use a Global Aurora.

93
00:03:50,910 --> 00:03:51,990
So let's have a look.

94
00:03:51,990 --> 00:03:54,030
We have us-east-1 as our PRIMARY region,

95
00:03:54,030 --> 00:03:56,640
which is where the applications do the read and writes,

96
00:03:56,640 --> 00:03:59,790
and then we'll set up a SECONDARY region in eu-west-1

97
00:03:59,790 --> 00:04:01,260
where some replication happening

98
00:04:01,260 --> 00:04:03,600
with a global database of Aurora,

99
00:04:03,600 --> 00:04:05,790
and the applications that it can do read-only

100
00:04:05,790 --> 00:04:07,530
from that setup.

101
00:04:07,530 --> 00:04:09,540
But in case us-east-1 fails,

102
00:04:09,540 --> 00:04:11,550
then we can fail over to eu-west-1

103
00:04:11,550 --> 00:04:15,240
by promoting it as a read/write Aurora cluster.

104
00:04:15,240 --> 00:04:17,279
Aurora also has an integration

105
00:04:17,279 --> 00:04:19,380
with machine learning services within AWS.

106
00:04:19,380 --> 00:04:21,120
So the idea with Aurora Machine Learning

107
00:04:21,120 --> 00:04:23,490
is that you can have ML based predictions

108
00:04:23,490 --> 00:04:25,830
to your applications via the SQL interface.

109
00:04:25,830 --> 00:04:27,960
It's a simple, optimized and secure integration

110
00:04:27,960 --> 00:04:31,800
between Aurora and different AWS machine learning services.

111
00:04:31,800 --> 00:04:34,200
So two supported services are SageMaker,

112
00:04:34,200 --> 00:04:35,310
which allows you to use

113
00:04:35,310 --> 00:04:37,590
any kind of machine learning model in the backend

114
00:04:37,590 --> 00:04:40,710
or Amazon Comprehend if you want to do sentiment analysis.

115
00:04:40,710 --> 00:04:42,240
Now, you don't need to be an expert in SageMaker

116
00:04:42,240 --> 00:04:44,250
or Comprehend, you just need to know that

117
00:04:44,250 --> 00:04:46,530
Aurora has an integration with those.

118
00:04:46,530 --> 00:04:48,731
So in order to use Aurora Machine Learning,

119
00:04:48,731 --> 00:04:51,690
you don't need to have a machine learning experience.

120
00:04:51,690 --> 00:04:54,990
And the use cases for this would be to have fraud detection,

121
00:04:54,990 --> 00:04:56,580
ads targeting, sentiment analysis,

122
00:04:56,580 --> 00:04:59,400
or product recommendation all within Aurora.

123
00:04:59,400 --> 00:05:01,620
So to give you the architecture idea,

124
00:05:01,620 --> 00:05:03,270
Aurora is going to be connected

125
00:05:03,270 --> 00:05:06,150
to the machine learning services in AWS.

126
00:05:06,150 --> 00:05:09,150
And your application can just run a very simple SQL query.

127
00:05:09,150 --> 00:05:11,820
For example, what are the recommended products?

128
00:05:11,820 --> 00:05:13,800
Aurora will send some data

129
00:05:13,800 --> 00:05:15,600
into the machine learning services

130
00:05:15,600 --> 00:05:17,250
such as, for example, the user's profile,

131
00:05:17,250 --> 00:05:18,930
the shopping history, et cetera, et cetera.

132
00:05:18,930 --> 00:05:21,000
And then the machine learning service

133
00:05:21,000 --> 00:05:23,430
will return a prediction directly to Aurora.

134
00:05:23,430 --> 00:05:26,940
For example, the user should buy a red shirt and blue pants,

135
00:05:26,940 --> 00:05:29,400
and then Aurora can just return the query results

136
00:05:29,400 --> 00:05:31,650
to the application all through

137
00:05:31,650 --> 00:05:35,520
as a result of the SQL query, which is very handy.

138
00:05:35,520 --> 00:05:39,180
So let's talk about Babelfish for Aurora PostgreSQL.

139
00:05:39,180 --> 00:05:41,130
So this is a feature that allows

140
00:05:41,130 --> 00:05:44,670
Amazon Aurora PostgreSQL to understand commands

141
00:05:44,670 --> 00:05:47,760
that are targeted for Microsoft SQL Server

142
00:05:47,760 --> 00:05:49,410
using the language T-SQL.

143
00:05:49,410 --> 00:05:51,210
So let me explain so it's clearer.

144
00:05:51,210 --> 00:05:54,750
If you have an application in your company today

145
00:05:54,750 --> 00:05:57,720
that's using Microsoft SQL Server as a database,

146
00:05:57,720 --> 00:06:00,060
then your applications are going to be written

147
00:06:00,060 --> 00:06:01,920
and they're going to use a driver called

148
00:06:01,920 --> 00:06:03,990
the SQL Server Client Driver,

149
00:06:03,990 --> 00:06:05,550
which is going to send the commands

150
00:06:05,550 --> 00:06:08,910
to your Microsoft SQL server using T-SQL.

151
00:06:08,910 --> 00:06:11,220
But tomorrow you want to migrate to the cloud.

152
00:06:11,220 --> 00:06:13,620
And so you migrate to Aurora PostgreSQL,

153
00:06:13,620 --> 00:06:16,380
which is a scalable database in the cloud that you like,

154
00:06:16,380 --> 00:06:19,200
but the engine is PostgreSQL.

155
00:06:19,200 --> 00:06:22,650
So that means that your applications must be converted

156
00:06:22,650 --> 00:06:24,780
to using the PostgreSQL driver

157
00:06:24,780 --> 00:06:27,060
and the SQL language is a little bit different.

158
00:06:27,060 --> 00:06:29,790
It's using the PL/pgSQL language.

159
00:06:29,790 --> 00:06:30,690
So it's just a different language

160
00:06:30,690 --> 00:06:32,490
you're going to remember the name of it.

161
00:06:32,490 --> 00:06:34,770
So the idea is that how do we make sure

162
00:06:34,770 --> 00:06:38,670
that our SQL Server application does not have to be

163
00:06:38,670 --> 00:06:40,740
migrated to be rewritten?

164
00:06:40,740 --> 00:06:41,573
For this we use Babelfish

165
00:06:41,573 --> 00:06:45,840
and Babelfish is going to be enabled on Aurora PostgreSQL,

166
00:06:45,840 --> 00:06:48,360
and this allows your application

167
00:06:48,360 --> 00:06:51,270
to just communicate to Aurora PostgreSQL

168
00:06:51,270 --> 00:06:54,300
using the T-SQL language through Babelfish.

169
00:06:54,300 --> 00:06:56,340
And so there is almost nothing to change.

170
00:06:56,340 --> 00:06:58,410
So that means that your SQL Server applications

171
00:06:58,410 --> 00:07:00,870
can now work on Aurora PostgreSQL

172
00:07:00,870 --> 00:07:05,340
with little to no code changes using the same driver.

173
00:07:05,340 --> 00:07:06,660
And so this is very handy

174
00:07:06,660 --> 00:07:09,000
because well, migrations are super easy.

175
00:07:09,000 --> 00:07:11,820
Now to do the migration to use something called,

176
00:07:11,820 --> 00:07:13,380
and we'll see this later on this course,

177
00:07:13,380 --> 00:07:17,820
something called AWS SCT and DMS to migrate from,

178
00:07:17,820 --> 00:07:20,760
for example, SQL Server to Aurora PostgreSQL.

179
00:07:20,760 --> 00:07:23,910
But Babelfish is here to do the translation

180
00:07:23,910 --> 00:07:27,120
of T-SQL queries into Aurora PostgreSQL.

181
00:07:27,120 --> 00:07:28,380
So that's it for this lecture.

182
00:07:28,380 --> 00:07:31,330
I hope you liked it and I will see you in the next lecture.

